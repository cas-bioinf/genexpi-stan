---
title: "ODE model of gene regulation"
output: 
  html_notebook:
      fig_caption: TRUE
      code_folding: hide
---

```{r setup}
devtools::load_all()
library(cowplot)
library(tidyverse)
```


# Abstract


# Biological Background
In a very simplified form the [central dogma](https://en.wikipedia.org/wiki/Central_dogma_of_molecular_biology) of molecular biology may be paraphrased as follows: The DNA contains all of the instructions needed to run a cell and can be divided into coding and non-coding regions. The coding regions of DNA can be transcribed to form messenger RNA (mRNA) molecule containing a mirror-copy of the coding region. The messenger RNA is then translated to create protein. Proteins then perform most of the actual functions of the cells, including control of transcription and translation. This process is regulated at all stages and involves many feedback loops: most importantly, the rate of transcription of a gene is controlled by the abundance of regulatory proteins binding to specific sequences of the DNA near the coding region. The rate of translation and degradation of mRNA can also be regulated separately by other proteins and the rate of degradation of proteins themselves is also affected by other proteins. There are many exceptions where the above simplification does not hold, but the vast majority of cellular life can be described in these terms. 

Understanding what are the regulations taking place is thus an important step in understanding how cells work. However, our ability to observe what happens in the cell is very limited: The only commonly available method that can capture information about all genes in a single experiment is measuring the concentration of mRNA which is in turn strongly related to expression (how many mRNAs are transcribed from the gene in a unit of time). Gathering expression data remains relatively expensive and except for the most studied organisms, at most several dozen whole genome expression experiments have been published.

It has been shown that mRNA and protein concentration are mostly correlated, however this relationship is imperfect (Maier et al. 2009; Gygi et al. 1999). Nevertheless, expression data is the best proxy for protein concentration available at the whole genome level and expression data are thus widely used to infer interactions that control transcription of genes.

# Scope
In this work we assume time series of expression.

Introduction. Titsias & Honkela

We tried to directly rephrase the Titsias & Honkela model in Stan and we ran into large computational difficulties, including several non-identifiabilities, that we were not able to resolve without modifying the model. The model presented here resulted from resolving those issues and a slight simplification of the model

Show the data, some expression profiles.

# Basics of The Model

In all of the following, $x_i$ is the true (unknown) expression of a target gene,$y_j$ the true protein concentration of a regulator,$\rho_i$ the regulatory input, all three are functions of time while the rest are constants. The regulatory input is a linear combination of expression of regulators:

$$
\rho_i = \sum_j{w_{i,j}y_j} + b_i
$$
Then $x_i$ is driven by the following ordinary differential equation (ODE):
$$
\frac{\mathrm{d}x_i}{\mathrm{d}t} = s_i F(\rho_i) - d_i x_i
$$

$$
F(\rho_i) = \frac{1}{1 + e^{-\rho_i}}
$$

where $F$ is the regulatory response function, here the logistic sigmoid.

Our goal is, to use Stan to infere the parameters of this model ($s_i,w_{i,j},b_i, d_i$), given the observed expression of the target genes ($x_i$) and regulators ($y_i$) over time.

There are two forms of expression data available with widely different noise models: [microarray](https://en.wikipedia.org/wiki/DNA_microarray) and [RNA-seq](https://en.wikipedia.org/wiki/RNA-Seq). The former produces positive continuous measurements with approximately normal error while the latter produces count data with negative-binomial distribution. The datasets we are interested in come from microarray experiments so we will focus on those, but using RNA-seq means just changing the observation model. For microarrays, the observation model can be treated as a truncated normal:

$$
\tilde{x_i}(t) \sim N(x_i(t), \sigma_{abs} + x_i(t)\sigma_{rel})  \mathop{|} \tilde{x_i}(t) > 0
$$

The two error terms represent the fixed absolute error ($\sigma_{abs}$) which is the result of technical noise in the microarray platform and the relative error ($\sigma_{rel}$) wich represents the uncaptured biological variation which tend to be proportional to the expresssion of the genes. 

For the regulator(s) there are two possible regimes: a) the expression of the regulators is observed and the protein concentration is assumed to be indentical to the true expression or b) the $y$ is estimated only through its influence on $x$. In case a), the exact same error model applies to regulators.

# Modelling Regulator Expression

To solve the regulation ODE numerically, we need to have $y_i$ available at much finer intervals than the available measurements (1-2 minute intervals have proven sufficient). Initially, we considered Gaussian Processes (as @titsiashonkela), but those introduced computational issues and we switched to B-splines which have less theoretical appeal, but introduce fewer parameters and were easier to fit.

We however need to ensure that $y_i$ are positive. After some early setbacks with the ```log1pexp`` transform ($x^+ = ln(1+e^x)$), we settled to simply subtract the minimum of the spline from all points[^1], i.e. given the spline basis $B$ we get:

$$
\begin{aligned}
\bar{y_i} &= B\alpha_i \\
y_i &= c_{scale}(\bar{y_i} - \min{\bar{y_i}}) + \beta_i \\
\alpha_i &\sim N(0,1) \\
\beta_i &\sim HalfNormal(0, \sigma_\beta)
\end{aligned}
$$

Where $\alpha_i$ is a column vector of spline coefficients, $\beta_i$ serves as intercept. The scaling constant $c_{scale}$ and $\sigma_\beta$ reflect the range of the data and are given by the user.

[^1]: We now believe that the initial problems were not caused by ```log1pexp``` but by other parts of the model, however, the $\min$ transform is working well and there is currently no incentive to replace it. Note that $\min{\bar{y_i}}$ is mostly a smooth function of $\alpha_i$.

# Solving the ODE

It is a bit tricky to use Stan's built-in ODE solver with spline as one of the parameters driving ODE evolution as it needs the value of $y_i$ at arbitrary time points. The most straightforward way - linearly interpolating between precomputed discrete values of $y_i$ requires some hacks and breaks the solver. In principle, $\alpha_i$ could be given to the ODE solver and the spline basis computed for each timepoint the solver needs, but this seemed cumbersome. Instead we decided to follow the approach of @titsiashonkela. First we can observe that the regulation ODE is linear in $x_i$ and can be solved for $t \geq 0$:

$$
x_i(t) = \eta_i e^{-d_i t} + s_i \int_0^t F(\rho_i) e^{-d_i(t-u)} \mathrm{d}u
$$
Where $\eta_i$ is the concentration of the target at $t=0$. We then solve the resulting integral numerically via [trapezoid rule](https://en.wikipedia.org/wiki/Trapezoidal_rule)[^2]. Assuming unit timestep, $x_i$ can be computed in a single for loop:

$$
\begin{aligned}
\chi_i(0) &= -\frac{1}{2} F(\rho_i(0)) \\
\chi_i(t + 1) &= (\chi_i(t) + F(\rho_i(t)))d_i \\
x_i(t) &= \eta_i e^{-d_i t} + s_i(\chi_i(t) + \frac{1}{2}F(\rho_i(t)))
\end{aligned}
$$

[^2]: Trapezoid rule agrees well with the results of solving the ODE with RK45, while the simpler midpoint rule has significant bias even when the time steps are small.

# Identifiability

The model, as given above is biologically relevant, but has multiple identifiability issues, all of which can be demonstrated with just a single regulator and a single target, so we will drop parameter indicies for the rest of this section. The first non-identifiability arises with $w$ and $b$ if all values of $\rho$ fall on the tail of the sigmoid, which is approximately linear. In this case, the walue of $F(\rho)$ becomes insensitive to linear transformations of $w$ and $b$:

```{r}
time <- seq(0,2,length.out = 100)
regulator <- sin(time * 4) + 1

params1 <- c(degradation = 0.5, bias = -3, sensitivity = 1, weight = 5, basal_transcription = 0, protein = approxfun(time, regulator, rule=2));
target1 <-  ode( y = c(x = 0), times = time, func = target_ODE, parms = params1, method = "ode45")[,"x"];

params2 <- c(degradation = 0.5, bias = -6, sensitivity = 1, weight = 10, basal_transcription = 0, protein = approxfun(time, regulator, rule=2));
target2 <-  ode( y = c(x = 0), times = time, func = target_ODE, parms = params2, method = "ode45")[,"x"];

params3 <- c(degradation = 0.5, bias = -30, sensitivity = 1, weight = 50, basal_transcription = 0, protein = approxfun(time, regulator, rule=2));
target3 <-  ode( y = c(x = 0), times = time, func = target_ODE, parms = params3, method = "ode45")[,"x"];

params_to_legend <- function(params) {
  paste0("w = ", params["weight"], ", b = ", params["bias"])
}

data.frame(time = time, regulator = regulator, target1 = target1, target2 = target2, target3 = target3) %>%
  gather("profile","expression", -time) %>%
  ggplot(aes(x = time, y = expression, color = profile)) + 
  geom_line() + 
  scale_color_hue(labels = c("regulator", params_to_legend(params1), params_to_legend(params2), params_to_legend(params3))) + ggtitle("Non-identifiability due to w and b","All targets have s = 1, d = 0.5")
```
Transformations of $s$ and $d$ together may also have very minor effect on the resulting expression. While the resulting expression profiles are more different than in the previous case, those differences are still very small compared to the noise observed in real data:
```{r, fig.cap="The red dots represent measurements that have approximately equal likelihood for each of the shown true target profiles, assuming $\\sigma \\simeq 0.5$"}
time <- seq(0,2,length.out = 100)
regulator <- sin(time * 4) + 1

params1 <- c(degradation = 5, bias = -1, sensitivity = 10, weight = 1, basal_transcription = 0, protein = approxfun(time, regulator, rule=2));
target1 <-  ode( y = c(x = 1), times = time, func = target_ODE, parms = params1, method = "ode45")[,"x"];

params2 <- c(degradation = 10, bias = -1, sensitivity = 20, weight = 1, basal_transcription = 0, protein = approxfun(time, regulator, rule=2));
target2 <-  ode( y = c(x = 1), times = time, func = target_ODE, parms = params2, method = "ode45")[,"x"];

params3 <- c(degradation = 100, bias = -1, sensitivity = 200, weight = 1, basal_transcription = 0, protein = approxfun(time, regulator, rule=2));
target3 <-  ode( y = c(x = 1), times = time, func = target_ODE, parms = params3, method = "ode45")[,"x"];

params_to_legend <- function(params) {
  paste0("s = ", params["sensitivity"], ", d = ", params["degradation"])
}

measured_data = data.frame(profile = "measured", time = seq(0,2,length.out = 9), 
                           expression = c(1,1.7,1.4,0.8, 0.7,0.3,0.7,1.4,1.5))


data.frame(time = time, regulator = regulator, target1 = target1, target2 = target2, target3 = target3) %>%
  gather("profile","expression", -time) %>%
  ggplot(aes(x = time, y = expression, color = profile)) + geom_line() + 
  geom_point(data = measured_data, color = "#ba1b1d", size = 3) +
  scale_color_hue(labels = c("regulator",params_to_legend(params1), params_to_legend(params2), params_to_legend(params3))) + ggtitle("Non identifiability due to s and d","All targets have w = 1, b = -1")
```
There is also a non-identifiability when $w = 0$ as $s$ and $b$ become redundant. Even worse, some of the solutions with $w = 0$ might not be distinguishable form solutions with $|w| \gg 0$. This might also induce non-identifiability in the initial condition $\eta$ as it is much less constrained by data. Once again the expression profiles are not identical, but are close enough that given the amount of noise, non-negligible posterior mass can be found for all of them:

```{r, fig.cap="The red dots represent measurements that have approximately equal likelihood for each of the shown true target profiles, assuming $\\sigma \\simeq 0.5$"}
time <- seq(0,2,length.out = 100)
regulator <- sin(time * 4) + 1

params1 <- c(degradation = 3, bias = -1, sensitivity = 3, weight = 5, basal_transcription = 0, protein = approxfun(time, regulator, rule=2));
target1 <-  ode( y = c(x = 1.5), times = time, func = target_ODE, parms = params1, method = "ode45")[,"x"];

params2 <- c(degradation = 3.4, bias = 0, sensitivity = 6, weight = 0, basal_transcription = 0, protein = approxfun(time, regulator, rule=2));
target2 <-  ode( y = c(x = 1.6), times = time, func = target_ODE, parms = params2, method = "ode45")[,"x"];

params3 <- c(degradation = 10, bias = 0, sensitivity = 16, weight = 0, basal_transcription = 0, protein = approxfun(time, regulator, rule=2));
target3 <-  ode( y = c(x = 2.5), times = time, func = target_ODE, parms = params3, method = "ode45")[,"x"];


params_to_legend <- function(params) {
  paste0("s = ", params["sensitivity"],", w = ", params["weight"], ", b = ", params["bias"], ", d = ", params["degradation"])
}

measured_data = data.frame(profile = "measured", time = seq(0,2,length.out = 9), 
                           expression = c(1.8,0.9,1,0.66, 1.11,0.6,0.7,0.96,1.03))


data.frame(time = time, regulator = regulator, target1 = target1, target2 = target2, target3 = target3) %>%
  gather("profile","expression", -time) %>%
  ggplot(aes(x = time, y = expression, color = profile)) + geom_line() + 
  geom_point(data = measured_data, color = "#ba1b1d", size = 3) +
  scale_color_hue(labels = c("regulator",params_to_legend(params1), params_to_legend(params2), params_to_legend(params3))) + ggtitle("Non identifiability between w=0 and w > 0")
```
Last but not least, it is also possible to get distinct solution with different sign of $w$:

```{r, fig.cap="The red dots represent measurements that have approximately equal likelihood for each of the shown true target profiles, assuming $\\sigma \\simeq 0.5$"}
time <- seq(0,2,length.out = 100)
regulator <- (sin(time * 1.5) ^ 2) * 2

params1 <- c(degradation = 2, bias = -1, sensitivity = 3, weight = 5, basal_transcription = 0, protein = approxfun(time, regulator, rule=2));
target1 <-  ode( y = c(x = 0), times = time, func = target_ODE, parms = params1, method = "ode45")[,"x"];

params2 <- c(degradation = 1.4, bias = 10, sensitivity = 2.5, weight = -5, basal_transcription = 0, protein = approxfun(time, regulator, rule=2));
target2 <-  ode( y = c(x = 0), times = time, func = target_ODE, parms = params2, method = "ode45")[,"x"];


params_to_legend <- function(params) {
  paste0("s = ", params["sensitivity"],", w = ", params["weight"], ", b = ", params["bias"], ", d = ", params["degradation"])
}

measured_data = data.frame(profile = "measured", time = seq(0,2,length.out = 9), 
                           expression = c(0.2,0.35,0.61,1.03, 1.11,1.42,1.07,1.76,1.23))


data.frame(time = time, regulator = regulator, target1 = target1, target2 = target2) %>%
  gather("profile","expression", -time) %>%
  ggplot(aes(x = time, y = expression, color = profile)) + geom_line() + 
  geom_point(data = measured_data, color = "#ba1b1d", size = 3) +
  scale_color_hue(labels = c("regulator",params_to_legend(params1), params_to_legend(params2))) + ggtitle("Non identifiability between w < 0 and w > 0")
```

There are probably many more non-identified scenarios, especially when multiple targets targets are involved, but the above are of the type we have actually encountered with real data.

## Reparametrization

First we realized that when there is a good fit with $w < 0$ and a similarly good one with $w > 0$ are, there is nothing we can do to make the model identifiable, so we decided to make the user specify the expected sign for all $w_{i,j}$ as data. This is not a big hindrance as this type of regulation model is mostly employed to test direct regulations by transcription factors which are expected to always have $w > 0$.

Some of the non-identifiabilities are a result of the fact, that some of the roles the parameters play in the model are partially shared by muliple parameters. To get rid of those complex dependencies, we introduced several reparametrizations. The only parameter we kept directly is the degradation parameter $d_i$, which also has the nice property that it does not depend on the scale of the expression data (only on the length of the timestep).

Instead of $s_i,b_i$ and $w_{i,j}$, we introduce $\mu^{\rho}_i$, the mean regulatory input, $\sigma^{\rho}_i$, the sd of the regulatory input and $a_i$ the asymptotic normalized state. All of those parameters are also decoupled from the actual values of the expression data. In the case of a single regulator $y$, the new parameters are connected with the original parameters as follows:

$$
\begin{align}
w_i &= \mathrm{sgn}(w_i) \frac{\sigma^{\rho}_i}{Var(\rho_i)} \\
b_i &= \mu^{\rho}_i - w_i E(\rho_i) \\
s_i &= \frac{a_i d_i \max\tilde{x_i} }{ E(F(\rho_i)) }
\end{align}
$$
The interpretion of $a_i$ is that if $\rho_i \gg 0$ and $t \rightarrow \infty$ then $\rightarrow$. Also note that using $\max\tilde{x_i}$ means the model is not, strictly speaking generative, as we cannot generate $\tilde{x_i}$ before we generate $s_i$, but this has shown to not be a problem in practice.

When there are multiple regulators, their relative weights are described by a simplex parameter $\gamma_i$ and $w_i$ is redistributed among them so that:
$$
\begin{align}
w_{i,j} &= \gamma_{i,j}w_i \\
\sum_j \gamma_{i,j} &= 1, \gamma_{i,j} > 0 \\
\end{align}
$$
This not only helped identify the posterior but it is also much easier to specify priors for those parameters!

We ended up with:
$$
\begin{align}
\mu^{\rho}_i &\sim N(0,\tau_{\rho,\mu}) &\\
\sigma^{\rho}_i &\sim N(0,\tau_{\rho,\sigma})  &| \sigma^{\rho}_i > 0 \\
a_i &\sim  N(1,\tau_{a})  &| a_i > 0 \\
log(d_i) &\sim N(\nu_d,\tau_d) & 
\end{align}
$$
Where all the hyperparameters are given by user, but sensible defaults can be given as the hyperparameters are decoupled from the scale of the data. Since the sigmoid $F$ is mostly saturated outside $[-5,5]$, we use $\tau_{\rho,\mu} = \tau_{\rho,\sigma} = 5$. Further we expect $a_i$ should lie mostly in $[0,2]$ (e.g. if given more time the gene will unlikely raise to more than twice the maximum observed), giving $\tau_a = \frac{1}{2}$ and finally we expect degradation to be non-negligible but less than 1 (e.g. all mRNA degrading in a single unit of time), giving $\nu_d = -2$ and $\tau_d = 1$.

## The constant synthesis model

To get rid of the non-identifiabilities connected with $w = 0$, we first try to fit a simpler *constant synthesis* model to each target separately, this model is given by:

$$
\frac{\mathrm{d}x_i}{\mathrm{d}t} = s'_i - d'_i x_i
$$
As in the general model, the constant synthesis model is not always well identified with this representation and we also introduce $a'_i$ as the asymptotic normalized state.

$$
s'_i = a'_i d'_i \max\tilde{x_i}
$$
This also lets us use the same priors for $a'_i$ and $d'_i$ as for $a_i$ and $d_i$ respectively.

If the target is "reasonably well" fit with the constant synthesis model, it is not considered for the full model, because it could then be fit by any regulator, simply be setting $w = 0$. The quality of the model fit is assessed with WAIC, see discussion below for further details.

# Estimating regulator expression from known targets

## Transferring the learned expression to other fits

# Fitting new targets

# Assesing model fit

In the following, we treat $\sigma_{abs}$ and $\sigma_{rel} as given. While they can be fit in principle with the model, the resulting $\sigma_{rel}$ values tended to be unrealistically high and most fits unexpectedly poor as a consequence.

How high is the level of technical noise in microarray data? (https://biologydirect.biomedcentral.com/articles/10.1186/1745-6150-2-9) 
suggests that technical variation is constant (and with sigma around 0.1). But we also have biological variability / stochasticity, that is proportional.


First refine regulator by working with known targets.

Reducing actual posterior to multivariate normal and using to fit other genes.

WAIC to quickly assess fit quality


